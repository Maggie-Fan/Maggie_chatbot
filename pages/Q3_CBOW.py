# Q3_CBOW.py

import streamlit as st
from gensim.models import Word2Vec
from gensim.utils import simple_preprocess
from gensim.parsing.preprocessing import remove_stopwords

st.set_page_config(page_title="Q3 CBOW ", layout="wide")
st.title("ğŸ”¤ Q3: CBOW Word2Vec ")

# === åƒæ•¸è¨­å®š ===
vector_size = 100
window_size = 5
min_count = 1
workers = 4

# === èªæ–™ä¾†æº ===
sentences = [
    "Fifteen people in South Korea were injured, two of them seriously, after a pair of fighter jets accidentally dropped eight bombs in a civilian district on Thursday during a live-fire military exercise, local media reported",
    "The incident involving the Air Force KF-16 aircraft, in the city of Pocheon near North Korea, was part of routine drills held by the South to maintain combat readiness against potential attacks from the North",
    "South Korea's Air Force said that it was investigating the incident and apologised for the damage, adding it would provide compensation to those affected",
    "While shells from live firing exercises sometimes land near civilian residences, they rarely cause injuries",
    "According to local media reports, two people suffered fractures to their necks and shoulders",
    "The military said the pilot of one of the jets inputted the wrong coordinates by mistake, causing the bombs to drop in the civilian community",
    "Investigators have yet to determine why the second jet dropped its bombs, the military said, adding all live-fire exercises will be suspended",
    "One church building and houses were also damaged as a result of the incident",
    "South Korea and the US are set to run combined drills from March 10 to March 20 - the first since US president Donald Trump's return to the White House",
    "This comes at a time when the two countries are increasingly wary of the growing alliance between North Korea and Russia",
]

# === é è™•ç†èªæ–™ ===
tokenized = [simple_preprocess(remove_stopwords(sentence)) for sentence in sentences]

# === ä½¿ç”¨ cache è¨“ç·´ CBOW æ¨¡å‹ ===
@st.cache_resource
def train_cbow_model(tokenized_sentences):
    model = Word2Vec(tokenized_sentences, vector_size=vector_size, window=window_size, min_count=min_count, workers=workers, sg=0)
    return model

cbow_model = train_cbow_model(tokenized)

# === é¡¯ç¤ºè©å½™è¡¨ ===
with st.expander("ğŸ“– æŸ¥çœ‹ CBOW è©å½™è¡¨"):
    st.write(cbow_model.wv.index_to_key)

# === æŸ¥è©¢ç›¸ä¼¼è©å€å¡Š ===
user_input = st.text_input("ğŸ” è¼¸å…¥ä¸€å€‹è©ï¼Œæˆ‘æœƒé¡¯ç¤º CBOW çš„ç›¸ä¼¼è©", key="cbow_query")

if user_input:
    st.write(f"ä½ è¼¸å…¥çš„è©ï¼š `{user_input}`")
    if user_input in cbow_model.wv:
        similar = cbow_model.wv.most_similar(user_input, topn=5)
        st.markdown("**CBOW æ¨¡å‹ Top 5 ç›¸ä¼¼è©ï¼š**\n" + "\n".join([f"- {w} ({sim:.2f})" for w, sim in similar]))
    else:
        st.warning("âŒ è©å½™ä¸åœ¨æ¨¡å‹ä¸­ï¼Œè«‹å˜—è©¦å…¶ä»–è©ã€‚")